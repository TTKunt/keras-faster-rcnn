{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/yhenon/keras-frcnn/blob/master/keras_frcnn/FixedBatchNormalization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "from keras import initializers, regularizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedBatchNormalization(Layer):\n",
    "    \n",
    "    def __init__(self, epsilon=1e-3, axis=-1,\n",
    "                 weights=None, beta_init='zero', gamma_init='one',\n",
    "                 gamma_regularizer=None, beta_regularizer=None, **kwargs):\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.beta_init = initializers.get(beta_init)\n",
    "        self.gamma_init = initializers.get(gamma_init)\n",
    "        self.epsilon = epsilon\n",
    "        self.axis = axis\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.initial_weights = weights\n",
    "        super(FixedBatchNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_shape = [InputSpec(shape=input_shape)]\n",
    "        shape = (input_shape[self.axis], )\n",
    "        \n",
    "        self.gamma = self.add_weight(shape,\n",
    "                                     initializer = self.gamma_init,\n",
    "                                     regularizer = self.gamma_regularizer,\n",
    "                                     name = '{}_gamma'.format(self.name),\\\n",
    "                                     trainable = False)\n",
    "        self.beta = self.add_weight(shape,\n",
    "                                    initializer = self.beta_init,\n",
    "                                    regularizer = self.beta_regularizer,\n",
    "                                    name = '{}_beta'.format(self.name),\n",
    "                                    trainable = False)\\\n",
    "        \n",
    "        self.running_mean = self.add_weight(shape,\n",
    "                                           initializer = 'zero',\n",
    "                                           name = '{}_running_mean'.format(self.name),\n",
    "                                           trainable = False)\n",
    "        \n",
    "        self.running_std = self.add_weight(shape,\n",
    "                                           initializer = 'zero',\n",
    "                                          name = '{}_running_std'.format(self.name),\n",
    "                                          trainable = False)\n",
    "        \n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        assert self.built, 'Layer must be built before being called'\n",
    "        input_shape = K.int_shape(x)\n",
    "        \n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        \n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "        \n",
    "        if sorted(reduction_axes) == range(K.ndim(x))[:-1]:\n",
    "            x_normed = K.batch_normalization(\n",
    "                x, self.running_mean, self.running_std,\n",
    "                self.beta, self.gamma, epsilon=self.epsilon)\n",
    "            \n",
    "        else:\n",
    "            # need  broadcasting\n",
    "            broadcast_running_mean = K.reshape(self.running_mean, broadcast_shape)\n",
    "            broadcast_running_std  = K.reshape(self.running_std, broadcast_shape)\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            x_normed = K.batch_normalization(\n",
    "                x, broadcast_running_mean, broadcast_running_std,\n",
    "                broadcast_beta, broadcast_gamma, epsilon=self.epsilon)\n",
    "            \n",
    "        return x_normed\n",
    "    \n",
    "    def get_config(self):\n",
    "        \n",
    "        config = {'epsilon': self.epsilon,\n",
    "                  'axis': self.axis,\n",
    "                  'gamma_regularizer': self.gamma_regularizer.get_config() if self.gamma_regularizer else None,\n",
    "                  'beta_regularizer': self.beta_regularizer.get_config() if self.beta_regularizer else None}\n",
    "        \n",
    "        base_config = super(FixedBatchNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
