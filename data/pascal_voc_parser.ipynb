{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../pascal_voc_parser.py\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "def get_data(input_path, visualise=False):\n",
    "    \"\"\"Load data from an input file.\n",
    "      https://github.com/yhenon/keras-frcnn/blob/master/keras_frcnn/pascal_voc_parser.py#L19\n",
    "    Args: \n",
    "          input_path     (string)    :  path for the input file\n",
    "          visualise      (bool)      :  show images with annotation if True\n",
    "          \n",
    "    Returns:\n",
    "         all_imgs         (list)     : list of images\n",
    "         classes_count    (dict)     : dictionary containg classes information\n",
    "         class_mapping    (dict)     : dictionary containing class mapping\n",
    "    \"\"\"\n",
    "    all_imgs = []\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mapping = {}\n",
    "\n",
    "    data_paths = [os.path.join(input_path,s) for s in ['VOC2012']]\n",
    "\n",
    "\n",
    "    print('Parsing annotation files....')\n",
    "\n",
    "    for data_path in data_paths:\n",
    "\n",
    "        annot_path = os.path.join(data_path, 'Annotations')\n",
    "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
    "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets','Main','trainval.txt')\n",
    "        imgsets_path_test = os.path.join(data_path, 'ImageSets','Main','test.txt')\n",
    "\n",
    "        trainval_files = []\n",
    "        test_files = []\n",
    "        try:\n",
    "            with open(imgsets_path_trainval) as f:\n",
    "                for line in f:\n",
    "                    trainval_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            with open(imgsets_path_test) as f:\n",
    "                for line in f:\n",
    "                    test_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "            if data_path[-7:] == 'VOC2012':\n",
    "                # this is expected, most pascal voc distibutions dont have the test.txt file\n",
    "                pass\n",
    "            else:\n",
    "                print(e)\n",
    "\n",
    "        annots = [os.path.join(annot_path, s) for s in os.listdir(annot_path)]\n",
    "        idx = 0\n",
    "        for annot in annots:\n",
    "            try:\n",
    "                idx += 1\n",
    "\n",
    "                et = ET.parse(annot)\n",
    "                element = et.getroot()\n",
    "\n",
    "                element_objs = element.findall('object')\n",
    "                element_filename = element.find('filename').text\n",
    "                element_width = int(element.find('size').find('width').text)\n",
    "                element_height = int(element.find('size').find('height').text)\n",
    "\n",
    "                if len(element_objs) > 0:\n",
    "                    annotation_data = {'filepath': os.path.join(imgs_path, element_filename), 'width': element_width,\n",
    "                                       'height': element_height, 'bboxes': []}\n",
    "\n",
    "                    if element_filename in trainval_files:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "                    elif element_filename in test_files:\n",
    "                        annotation_data['imageset'] = 'test'\n",
    "                    else:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "\n",
    "                for element_obj in element_objs:\n",
    "                    class_name = element_obj.find('name').text\n",
    "                    if class_name not in classes_count:\n",
    "                        classes_count[class_name] = 1\n",
    "                    else:\n",
    "                        classes_count[class_name] += 1\n",
    "\n",
    "                    if class_name not in class_mapping:\n",
    "                        class_mapping[class_name] = len(class_mapping)\n",
    "\n",
    "                    obj_bbox = element_obj.find('bndbox')\n",
    "                    x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
    "                    y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
    "                    x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
    "                    y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
    "                    difficulty = int(element_obj.find('difficult').text) == 1\n",
    "                    annotation_data['bboxes'].append(\n",
    "                        {'class': class_name, 'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'difficult': difficulty})\n",
    "                all_imgs.append(annotation_data)\n",
    "\n",
    "                if visualise:\n",
    "                    img = cv2.imread(annotation_data['filepath'])\n",
    "                    for bbox in annotation_data['bboxes']:\n",
    "                        cv2.rectangle(img, (bbox['x1'], bbox['y1']), (bbox[\n",
    "                                        'x2'], bbox['y2']), (0, 0, 255))\n",
    "                    cv2.imshow('img', img)\n",
    "                    cv2.waitKey(0)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "    if 'bg' not in classes_count:\n",
    "        classes_count['bg'] = 0\n",
    "        class_mapping['bg'] = len(class_mapping)\n",
    "        \n",
    "        \n",
    "    print(\"Parsing annotation files Finished without error!\")\n",
    "    return all_imgs, classes_count, class_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    #all_imgs, classes_count, class_mapping = get_data('/home/abanihi/Documents/deep-data/VOCdevkit/')\n",
    "    #print(classes_count)\n",
    "    #print(class_mapping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
